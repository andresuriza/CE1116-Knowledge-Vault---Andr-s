---
Fecha de creaci贸n: 2025-08-06 16:59
Fecha de Modificaci贸n: 2025-08-06 16:59
tags:
  - inteligencia-artificial
Topic:
  - LLM
---

##  Idea/Concepto 


Los embeddings son vectores num茅ricos de alta dimensi贸n utilizados como par谩metros aprendidos por los modelos de machine learning, cuyo prop贸sito es codificar significado sem谩ntico y contextual de entradas como texto, im谩genes o audio. Estos significados se posicionan cerca unos de otros en el espacio vectorial dependiendo de que tan similares son. Sirven como la representaci贸n inicial de los tokens antes de ser refinados por capas, adem谩s de que se ajustan durante el entrenamiento utilizando el algoritmo de backpropagation. Los embeddings pueden ser contextuales si se utilizan en arquitecturas como Transformers, donde el significado de las palabras depende de aquellas que la rodean y su secuencia es definida por la codificaci贸n posicional.

##  Connections

- [[Tokenizaci贸n]]
- [[Redes Neuronales]]
- [[Mecanismo de atenci贸n utilizado en la arquitectura de Transformers]]
